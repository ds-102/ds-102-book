

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Regression, GLMs, and Bayesian vs Frequentist perspectives &#8212; Data, Inference, and Decisions</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/chapters/03/01_glms';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Data, Inference, and Decisions</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Data, Inference, and Decisions
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../01/intro.html">Chapter 1: Binary Decision-Making</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../01/01_decisions_and_errors.html">Binary Decision-Making and Error Rates</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01/02_hypothesis_testing.html">Hypothesis Testing and p-Values</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01/03_multiple_tests.html">Multiple Hypothesis Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01/04_binary_classification.html">Binary Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01/05_decision_theory.html">Decision Theory</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../02/intro.html">Chapter 2: Bayesian modeling</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../02/01_parameter_estimation.html">Parameter Estimation and Bayesian Inference Fundamentals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/02_hierarchical_models.html">Hierarchical Bayesian Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/03_graphical_models.html">Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/04_inference_sampling.html">Bayesian Inference and Sampling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="intro.html">Chapter 3: Prediction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../04/intro.html">Chapter 4: Causal Inference</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../04/01_association_correlation_causation.html">Understanding Association</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/02_quantifying_association.html">Quantifying Association</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/03_causality.html">Causality and Potential Outcomes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/04_randomized_experiments.html">Causality in Randomized Experiments</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/ds-102/ds-102-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/ds-102/ds-102-book/issues/new?title=Issue%20on%20page%20%2Fcontent/chapters/03/01_glms.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/content/chapters/03/01_glms.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Regression, GLMs, and Bayesian vs Frequentist perspectives</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup-and-imports">Setup and imports</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#log-transforming-data">Log-transforming data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-model">Bayesian model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#count-regression">Count regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#poisson-regression">Poisson regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#negative-binomial-regression">Negative binomial regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-happened-to-the-priors">What happened to the priors?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generalized-linear-models">Generalized Linear Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#frequentist-glms">Frequentist GLMs</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="regression-glms-and-bayesian-vs-frequentist-perspectives">
<h1>Regression, GLMs, and Bayesian vs Frequentist perspectives<a class="headerlink" href="#regression-glms-and-bayesian-vs-frequentist-perspectives" title="Permalink to this heading">#</a></h1>
<section id="setup-and-imports">
<h2>Setup and imports<a class="headerlink" href="#setup-and-imports" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="kn">import</span> <span class="nn">bambi</span> <span class="k">as</span> <span class="nn">bmb</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">8</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="ne">----&gt; </span><span class="mi">8</span> <span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="kn">import</span> <span class="nn">bambi</span> <span class="k">as</span> <span class="nn">bmb</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> <span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;pymc&#39;
</pre></div>
</div>
</div>
</div>
<p>In this notebook, we’ll be working with a dataset containing information on wind turbines.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">turbines</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;turbines.csv&#39;</span><span class="p">)</span>
<span class="c1"># The &quot;year&quot; column contains how many years since the year 2000</span>
<span class="n">turbines</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">turbines</span><span class="p">[</span><span class="s1">&#39;p_year&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2000</span>
<span class="n">turbines</span> <span class="o">=</span> <span class="n">turbines</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;p_year&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">turbines</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>t_state</th>
      <th>t_built</th>
      <th>t_cap</th>
      <th>year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AK</td>
      <td>6</td>
      <td>390.0</td>
      <td>-3.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AK</td>
      <td>6</td>
      <td>475.0</td>
      <td>-1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AK</td>
      <td>2</td>
      <td>100.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>AK</td>
      <td>1</td>
      <td>1500.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>AK</td>
      <td>1</td>
      <td>100.0</td>
      <td>2.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Turbines in Oklahoma from 2000 on</span>
<span class="n">ok_filter</span> <span class="o">=</span> <span class="p">(</span><span class="n">turbines</span><span class="o">.</span><span class="n">t_state</span> <span class="o">==</span> <span class="s1">&#39;OK&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">turbines</span><span class="o">.</span><span class="n">year</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">ok_turbines</span> <span class="o">=</span> <span class="n">turbines</span><span class="p">[</span><span class="n">ok_filter</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;year&#39;</span><span class="p">)</span>
<span class="n">ok_turbines</span><span class="p">[</span><span class="s2">&quot;totals&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">ok_turbines</span><span class="p">[</span><span class="s2">&quot;t_built&quot;</span><span class="p">])</span>
<span class="c1"># Log-transform the counts, too</span>
<span class="n">ok_turbines</span><span class="p">[</span><span class="s2">&quot;log_totals&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ok_turbines</span><span class="p">[</span><span class="s2">&quot;totals&quot;</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ok_turbines</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="s1">&#39;totals&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ok_turbines</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="s1">&#39;totals&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 640x480 with 0 Axes&gt;
</pre></div>
</div>
<img alt="../../../_images/1eb345793dfedf372a5b82217f6c26057489aa3395538fe1b81a982741d0c2e7.png" src="../../../_images/1eb345793dfedf372a5b82217f6c26057489aa3395538fe1b81a982741d0c2e7.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 640x480 with 0 Axes&gt;
</pre></div>
</div>
<img alt="../../../_images/788e2c1ae7b69dcb64986c5443a57aa78e50cc508b0827ae48d4a1f553f4090e.png" src="../../../_images/788e2c1ae7b69dcb64986c5443a57aa78e50cc508b0827ae48d4a1f553f4090e.png" />
</div>
</div>
<p>Recall our problem setup:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X\)</span>: an <span class="math notranslate nohighlight">\(n \times d\)</span> matrix, where each row is a data point, and each column is a feature (fixed)</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta\)</span>: a <span class="math notranslate nohighlight">\(d\)</span>-dimensional vector with one coefficient for each feature (random, unknown: this is what we want)</p></li>
<li><p><span class="math notranslate nohighlight">\(y\)</span>: an <span class="math notranslate nohighlight">\(n\)</span>-dimensional vector, with a number (response variable / dependent variable) that we want to predict for each data point (random, because it depends on <span class="math notranslate nohighlight">\(\beta\)</span> and on some error, often captured in a noise vector <span class="math notranslate nohighlight">\(\epsilon\)</span>)</p></li>
</ul>
<p>The likelihood <span class="math notranslate nohighlight">\(p(y|\beta)\)</span> usually describes the error model: in standard least squares regression, it’s</p>
<div class="math notranslate nohighlight">
\[
y|\beta \sim N(X\beta, \sigma^2 I_n)
\]</div>
<p>Let’s think about the implicit assumptions we’re making by choosing this likelihood. Recall that for the normal distribution, we’re very unlikely to see values more than 3<span class="math notranslate nohighlight">\(\sigma\)</span> away from the mean. That means that we’re implicitly assuming that the vast majority of <span class="math notranslate nohighlight">\(y\)</span>-values we see will be within 3<span class="math notranslate nohighlight">\(\sigma\)</span> of the mean (i.e., the prediction <span class="math notranslate nohighlight">\(X\beta\)</span>).</p>
<section id="log-transforming-data">
<h3>Log-transforming data<a class="headerlink" href="#log-transforming-data" title="Permalink to this heading">#</a></h3>
<p>Log-transforming the <span class="math notranslate nohighlight">\(y\)</span> variable is an important preprocessing step in many analyses: above, it turned an exponential-looking relationship into a linear one. We’re saying that <span class="math notranslate nohighlight">\(\log(y) = X\beta\)</span>, or equivalently that <span class="math notranslate nohighlight">\(y = \exp(X\beta)\)</span>.</p>
</section>
<section id="bayesian-model">
<h3>Bayesian model<a class="headerlink" href="#bayesian-model" title="Permalink to this heading">#</a></h3>
<p>We’re fitting what’s called a Generalized Linear Model (GLM) using PyMC3: we’ll learn more about GLMs a little later. The code used is adapted from <a class="reference external" href="https://docs.pymc.io/notebooks/GLM-linear.html">this tutorial</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ok_turbines</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>t_state</th>
      <th>t_built</th>
      <th>t_cap</th>
      <th>year</th>
      <th>totals</th>
      <th>log_totals</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>361</th>
      <td>OK</td>
      <td>1</td>
      <td>100.0</td>
      <td>1.0</td>
      <td>1</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>362</th>
      <td>OK</td>
      <td>113</td>
      <td>176250.0</td>
      <td>3.0</td>
      <td>114</td>
      <td>4.736198</td>
    </tr>
    <tr>
      <th>363</th>
      <td>OK</td>
      <td>182</td>
      <td>298200.0</td>
      <td>5.0</td>
      <td>296</td>
      <td>5.690359</td>
    </tr>
    <tr>
      <th>364</th>
      <td>OK</td>
      <td>40</td>
      <td>60000.0</td>
      <td>6.0</td>
      <td>336</td>
      <td>5.817111</td>
    </tr>
    <tr>
      <th>365</th>
      <td>OK</td>
      <td>85</td>
      <td>154500.0</td>
      <td>7.0</td>
      <td>421</td>
      <td>6.042633</td>
    </tr>
    <tr>
      <th>366</th>
      <td>OK</td>
      <td>91</td>
      <td>141900.0</td>
      <td>8.0</td>
      <td>512</td>
      <td>6.238325</td>
    </tr>
    <tr>
      <th>367</th>
      <td>OK</td>
      <td>153</td>
      <td>299100.0</td>
      <td>9.0</td>
      <td>665</td>
      <td>6.499787</td>
    </tr>
    <tr>
      <th>368</th>
      <td>OK</td>
      <td>195</td>
      <td>352260.0</td>
      <td>10.0</td>
      <td>860</td>
      <td>6.756932</td>
    </tr>
    <tr>
      <th>369</th>
      <td>OK</td>
      <td>257</td>
      <td>524900.0</td>
      <td>11.0</td>
      <td>1117</td>
      <td>7.018402</td>
    </tr>
    <tr>
      <th>370</th>
      <td>OK</td>
      <td>596</td>
      <td>1127050.0</td>
      <td>12.0</td>
      <td>1713</td>
      <td>7.446001</td>
    </tr>
    <tr>
      <th>371</th>
      <td>OK</td>
      <td>369</td>
      <td>648100.0</td>
      <td>14.0</td>
      <td>2082</td>
      <td>7.641084</td>
    </tr>
    <tr>
      <th>372</th>
      <td>OK</td>
      <td>710</td>
      <td>1399960.0</td>
      <td>15.0</td>
      <td>2792</td>
      <td>7.934513</td>
    </tr>
    <tr>
      <th>373</th>
      <td>OK</td>
      <td>602</td>
      <td>1457525.0</td>
      <td>16.0</td>
      <td>3394</td>
      <td>8.129764</td>
    </tr>
    <tr>
      <th>374</th>
      <td>OK</td>
      <td>323</td>
      <td>850725.0</td>
      <td>17.0</td>
      <td>3717</td>
      <td>8.220672</td>
    </tr>
    <tr>
      <th>375</th>
      <td>OK</td>
      <td>272</td>
      <td>543245.0</td>
      <td>18.0</td>
      <td>3989</td>
      <td>8.291296</td>
    </tr>
    <tr>
      <th>376</th>
      <td>OK</td>
      <td>33</td>
      <td>100050.0</td>
      <td>19.0</td>
      <td>4022</td>
      <td>8.299535</td>
    </tr>
    <tr>
      <th>377</th>
      <td>OK</td>
      <td>440</td>
      <td>1120550.0</td>
      <td>20.0</td>
      <td>4462</td>
      <td>8.403352</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gaussian_model</span> <span class="o">=</span> <span class="n">bmb</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">&#39;log_totals ~ year&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">ok_turbines</span><span class="p">)</span>
<span class="n">gaussian_trace</span> <span class="o">=</span> <span class="n">gaussian_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">random_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [log_totals_sigma, Intercept, year]
</pre></div>
</div>
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html">
    <div>
      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [8000/8000 00:03&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    </div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">gaussian_trace</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/60f2009f0dde1609997c19bd30c70abb24f163d774884886a10b483045b368c3.png" src="../../../_images/60f2009f0dde1609997c19bd30c70abb24f163d774884886a10b483045b368c3.png" />
</div>
</div>
<p>The plots on the left show histograms of the samples for each hidden variable (in this case, the hidden variables are the regression intercept, the regression slope (coefficient of x), and the standard deviation of the errors. The plots on the right show how those variables changed from sample to sample.</p>
<p>The mean of the coefficient for <code class="docutils literal notranslate"><span class="pre">year</span></code> is around 0.3. What does this mean? It means that for every unit increase in <code class="docutils literal notranslate"><span class="pre">year</span></code> (i.e., every year), we see a linear increase of about 0.3 in <code class="docutils literal notranslate"><span class="pre">log_totals</span></code>. But we’re not really interested in <code class="docutils literal notranslate"><span class="pre">log_totals</span></code>!</p>
<p>We’re really interested in how <code class="docutils literal notranslate"><span class="pre">year</span></code> affects the turbine count (rather than the log). Let <span class="math notranslate nohighlight">\(N_{t}\)</span> be the number of turbines in year <span class="math notranslate nohighlight">\(t\)</span>, and let <span class="math notranslate nohighlight">\(y_t = \log(N_t)\)</span> be what we’re predicting in the regression above. Then we have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
y_{t+1} = y_t + 0.3 \\
\log(N_{t+1}) = \log(N_t) + 0.3 \\
N_{t+1} = N_t e^{0.3}
\end{split}\]</div>
<p>In other words, every year, this regression tells us that the prediction is <span class="math notranslate nohighlight">\(e^{0.4}\)</span> times the value from the previous year. That’s the effect that log-transforming the data has on the output: instead of predicting an additive increase, we’re predicting a multiplicative increase.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.3498588075760032
</pre></div>
</div>
</div>
</div>
<p>That’s an increase of about <span class="math notranslate nohighlight">\(49\%\)</span> every year.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># From the graph above, it looks like the coefficient could </span>
<span class="c1"># reasonably be between 0.25 and 0.35. How does that affect</span>
<span class="c1"># the year-over-year change?</span>
<span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.25</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.35</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1.2840254166877414, 1.4190675485932573)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="count-regression">
<h2>Count regression<a class="headerlink" href="#count-regression" title="Permalink to this heading">#</a></h2>
<p>The regression model above works reasonably well, but it doesn’t account for the fact that the variable we’re predicting is a whole number (meaning that it takes values <span class="math notranslate nohighlight">\(0, 1, 2, 3, \ldots\)</span>). When we say that <span class="math notranslate nohighlight">\(y|\beta \sim N(X\beta, \sigma^2 I)\)</span>, and using log-transformed data for <span class="math notranslate nohighlight">\(y\)</span>, we’re implicitly saying that <span class="math notranslate nohighlight">\(y\)</span> can never be 0. Can we use a different likelihood that is designed specifically for this kind of data?</p>
<p>We’ve already seen one different model for the case where <span class="math notranslate nohighlight">\(y\)</span> is binary: logistic regression. In this section, we’ll explore two models for predicting count data: Poisson regression and negative binomial regression.</p>
<section id="poisson-regression">
<h3>Poisson regression<a class="headerlink" href="#poisson-regression" title="Permalink to this heading">#</a></h3>
<p>Recall that the <a class="reference external" href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson distribution</a> is a distribution over counts and count-like values. It has one <em>positive</em> parameter <span class="math notranslate nohighlight">\(\lambda\)</span> that represents its mean (and variance, too).</p>
<p>In Poisson regression, we’re going to assume a Poisson likelihood for each <span class="math notranslate nohighlight">\(y_i\)</span>. The parameter of the distribution must be positive, but <span class="math notranslate nohighlight">\(x_i^T\beta\)</span> could be negative. There are several ways to make the possibly-negative value into a positive one, but we’ll use <span class="math notranslate nohighlight">\(\exp(x_i^T \beta)\)</span> as the mean. This way, we don’t have to log-transform the data. We can write out our likelihood:</p>
<div class="math notranslate nohighlight">
\[
y_i | \beta \sim \text{Poisson}(\exp(x_i^T \beta))
\]</div>
<p>Let’s try it out in PyMC3! Even though the different likelihood means that we’re optimizing a completely different loss function, we only need to make a few tiny changes to our code from earlier:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">poisson_model</span> <span class="o">=</span> <span class="n">bmb</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">&#39;totals ~ year&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">ok_turbines</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="s1">&#39;poisson&#39;</span><span class="p">)</span>
<span class="n">poisson_trace</span> <span class="o">=</span> <span class="n">poisson_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">random_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [Intercept, year]
</pre></div>
</div>
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html">
    <div>
      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [8000/8000 00:03&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    </div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
</pre></div>
</div>
</div>
</div>
<p>One consequence of the Poisson likelihood is that <span class="math notranslate nohighlight">\(E[y|\beta] = exp(x_i^T \beta)\)</span>, which means that our interpretation of the coefficient(s) is the same as it was in the earlier case.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">poisson_trace</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/513f7b717762d11e2aa8a36d1049461de691470c4996433dc31ad66afae839e9.png" src="../../../_images/513f7b717762d11e2aa8a36d1049461de691470c4996433dc31ad66afae839e9.png" />
</div>
</div>
<p>Comparing this to the results from the Gaussian model, we can see that the posteriors are <strong>much</strong> narrower. On top of that, the values of the coefficient for <code class="docutils literal notranslate"><span class="pre">year</span></code> seem much smaller: whereas before we saw values around <span class="math notranslate nohighlight">\(0.3\)</span>, now it looks like the values are around 0.183.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.183</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.2008144080808307
</pre></div>
</div>
</div>
</div>
<p>This corresponds to only a <span class="math notranslate nohighlight">\(22.5\%\)</span> average growth rate, compared to our <span class="math notranslate nohighlight">\(35\%\)</span> average growth rate from the earlier model. Why are the results so different? Let’s think about the implicit assumptions we’re making when choosing a Poisson likelihood. The Poisson distribution’s mean is equal to its variance.</p>
<p>Clearly, the Poisson is a poor choice for fitting this data! When the model assumes a lower variance than is actually present in the data, we say that the data are <strong>overdispersed</strong> (i.e., that they’re too spread out relative to the model’s assumptions). We should choose a different distribution that gives us the ability to control the variance as well as the mean.</p>
<p>(Note that this wasn’t a problem with the normal likelihood earlier: because the normal distribution has two separate parameters for mean and variance, we can choose them separately to reflect the fact that the variance may be higher than the mean.)</p>
</section>
<section id="negative-binomial-regression">
<h3>Negative binomial regression<a class="headerlink" href="#negative-binomial-regression" title="Permalink to this heading">#</a></h3>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Negative_binomial_distribution">negative binomial distribution</a> is also a distribution over counts, but it’s more sophisticated than the Poisson distribution. We can think of it one of two ways:</p>
<ul class="simple">
<li><p>It’s the sum of <span class="math notranslate nohighlight">\(r\)</span> [Geometric random variables], each with parameter <span class="math notranslate nohighlight">\(p\)</span> (success probability).</p></li>
<li><p>It’s like a Poisson distribution if the mean parameter (<span class="math notranslate nohighlight">\(\lambda\)</span> above) were also random.</p></li>
</ul>
<p>There are several different ways to parametrize the negative binomial. How do we choose which one to use? There are two answers:</p>
<ol class="arabic simple">
<li><p>We want a parametrization that lets us choose the mean, since we want the mean value for <span class="math notranslate nohighlight">\(y_i\)</span> to be <span class="math notranslate nohighlight">\(\exp(x_i^T \beta)\)</span>.</p></li>
<li><p>Since we’re using PyMC3, we’re limited to whichever parametrization(s) it supports.</p></li>
</ol>
<p>Even though the form of the distribution is significantly more complex and manipulating it involves more work, using it in our regression model requires only a tiny change to what we were doing before:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">negbin_model</span> <span class="o">=</span> <span class="n">bmb</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">&#39;totals ~ year&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">ok_turbines</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="s1">&#39;negativebinomial&#39;</span><span class="p">)</span>
<span class="n">negbin_trace</span> <span class="o">=</span> <span class="n">negbin_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">random_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [totals_alpha, Intercept, year]
</pre></div>
</div>
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html">
    <div>
      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [8000/8000 00:04&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    </div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">negbin_trace</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/e22f5279fc97efdcb1bd4a3454f96f104d634325a37497cadedc603203d5b32a.png" src="../../../_images/e22f5279fc97efdcb1bd4a3454f96f104d634325a37497cadedc603203d5b32a.png" />
</div>
</div>
<p>Here, the posterior distribution for the <span class="math notranslate nohighlight">\(x\)</span> coefficient has a wider spread again. It looks like the mean is around <span class="math notranslate nohighlight">\(0.24\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.24</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.2712491503214047
</pre></div>
</div>
</div>
</div>
<p>This corresponds to a growth rate around <span class="math notranslate nohighlight">\(27\%\)</span>.</p>
</section>
<section id="what-happened-to-the-priors">
<h3>What happened to the priors?<a class="headerlink" href="#what-happened-to-the-priors" title="Permalink to this heading">#</a></h3>
<p>You may have noticed that I claimed we’re doing “Bayesian inference”, but there were no priors used above! By default, PyMC3 uses a “flat” prior, which is uniform over all real numbers. This is what’s called an “improper” prior, because it doesn’t and can’t integrate to 1 (or to any finite number).</p>
<p>You can specify priors for <span class="math notranslate nohighlight">\(\beta\)</span>: can you find out how using the documentation?</p>
</section>
</section>
<section id="generalized-linear-models">
<h2>Generalized Linear Models<a class="headerlink" href="#generalized-linear-models" title="Permalink to this heading">#</a></h2>
<p>By now, you’ve seen four different versions of regression in the Bayesian setting:</p>
<ul class="simple">
<li><p>Linear regression, for predicting real-valued outputs</p></li>
<li><p>Logistic regression, for predicting binary outputs (classification)</p></li>
<li><p>Poisson regression, for predicting counts</p></li>
<li><p>Negative binomial regression, for predicting counts</p></li>
</ul>
<p>Let’s review what they had in common and what was different between them:</p>
<ol class="arabic simple">
<li><p>For all four, computing our prediction for <span class="math notranslate nohighlight">\(y_i\)</span> begins with computing <span class="math notranslate nohighlight">\(x_i^T \beta\)</span>. This part is a <em>linear</em> function of <span class="math notranslate nohighlight">\(x_i\)</span>, even if we do something nonlinear with it later.</p></li>
<li><p>Each one had a different function that we used to compute the average value of <span class="math notranslate nohighlight">\(y_i\)</span> from <span class="math notranslate nohighlight">\(x_i^T \beta\)</span>. Since this function links the linearly transformed input <span class="math notranslate nohighlight">\(x\)</span> to the output <span class="math notranslate nohighlight">\(y\)</span>, you might expect us to call it the <strong>link function</strong>: this would make a lot of sense. However, the convention is to do the opposite, and call it the <strong>inverse link function</strong>. As you might expect from this name, the <strong>link function</strong> is the inverse of the inverse link function.</p></li>
<li><p>For each one, we used a different distribution for the likelihood. In all cases, the output of the function above was always the mean of this distribution.</p></li>
</ol>
<p>The following table summarizes the different choices of likelihood and link function for the four versions that we’ve seen:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Regression</p></th>
<th class="head text-left"><p>Inverse link function</p></th>
<th class="head text-left"><p>Link function</p></th>
<th class="head text-left"><p>Likelihood</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Linear</p></td>
<td class="text-left"><p>identity</p></td>
<td class="text-left"><p>identity</p></td>
<td class="text-left"><p>Gaussian</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Logistic</p></td>
<td class="text-left"><p>sigmoid</p></td>
<td class="text-left"><p><a class="reference external" href="https://en.wikipedia.org/wiki/Logit">logit</a></p></td>
<td class="text-left"><p>Bernoulli</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Poisson</p></td>
<td class="text-left"><p>exponential</p></td>
<td class="text-left"><p>log</p></td>
<td class="text-left"><p>Poisson</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Negative binomial</p></td>
<td class="text-left"><p>exponential</p></td>
<td class="text-left"><p>log</p></td>
<td class="text-left"><p>Negative binomial</p></td>
</tr>
</tbody>
</table>
<p>These ideas form the basis for what are known as Generalized Linear Models, or GLMs. Once we choose a link function and a likelihood distribution, our model is fully specified, and we can approximate the posterior distribution over the coefficients in <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
<section id="frequentist-glms">
<h3>Frequentist GLMs<a class="headerlink" href="#frequentist-glms" title="Permalink to this heading">#</a></h3>
<p>We’ll look at the same models we implemented before, but this time we’ll use the <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> package to look at things through a frequentist lens.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gaussian_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ok_turbines</span><span class="o">.</span><span class="n">totals</span><span class="p">),</span> <span class="n">ok_turbines</span><span class="o">.</span><span class="n">year</span><span class="p">,</span> 
    <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">gaussian_results</span> <span class="o">=</span> <span class="n">gaussian_model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gaussian_results</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:                 totals   No. Observations:                   17
Model:                            GLM   Df Residuals:                       16
Model Family:                Gaussian   Df Model:                            0
Link Function:               Identity   Scale:                          3.3610
Method:                          IRLS   Log-Likelihood:                -33.911
Date:                Thu, 15 Feb 2024   Deviance:                       53.776
Time:                        19:59:26   Pearson chi2:                     53.8
No. Iterations:                     3   Pseudo R-squ. (CS):             0.2027
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
year           0.5346      0.035     15.098      0.000       0.465       0.604
==============================================================================
</pre></div>
</div>
</div>
</div>
<p>This model’s results don’t look like the others, because it’s missing an intercept. We need to use the <code class="docutils literal notranslate"><span class="pre">add_constant</span></code> function in <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gaussian_model_intercept</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ok_turbines</span><span class="o">.</span><span class="n">totals</span><span class="p">),</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">ok_turbines</span><span class="o">.</span><span class="n">year</span><span class="p">),</span>
    <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">gaussian_results</span> <span class="o">=</span> <span class="n">gaussian_model_intercept</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gaussian_results</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:                 totals   No. Observations:                   17
Model:                            GLM   Df Residuals:                       15
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                          1.1810
Method:                          IRLS   Log-Likelihood:                -24.472
Date:                Thu, 15 Feb 2024   Deviance:                       17.716
Time:                        19:59:32   Pearson chi2:                     17.7
No. Iterations:                     3   Pseudo R-squ. (CS):             0.9131
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
const          3.2602      0.590      5.526      0.000       2.104       4.417
year           0.3023      0.047      6.435      0.000       0.210       0.394
==============================================================================
</pre></div>
</div>
</div>
</div>
<p>Take a minute to look over the results. What does it mean that the standard error for the estimated <code class="docutils literal notranslate"><span class="pre">year</span></code> coefficient is 0.047?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">poisson_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span>
    <span class="n">ok_turbines</span><span class="o">.</span><span class="n">totals</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">ok_turbines</span><span class="o">.</span><span class="n">year</span><span class="p">),</span>
    <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Poisson</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">poisson_results</span> <span class="o">=</span> <span class="n">poisson_model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">poisson_results</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:                 totals   No. Observations:                   17
Model:                            GLM   Df Residuals:                       15
Model Family:                 Poisson   Df Model:                            1
Link Function:                    Log   Scale:                          1.0000
Method:                          IRLS   Log-Likelihood:                -755.42
Date:                Thu, 15 Feb 2024   Deviance:                       1366.3
Time:                        19:59:33   Pearson chi2:                 1.20e+03
No. Iterations:                     5   Pseudo R-squ. (CS):              1.000
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
const          4.9697      0.023    219.386      0.000       4.925       5.014
year           0.1829      0.001    132.547      0.000       0.180       0.186
==============================================================================
</pre></div>
</div>
</div>
</div>
<p>The coefficients on <code class="docutils literal notranslate"><span class="pre">p_year</span></code> looks similar to what we got with the Bayesian approach. Notice that the standard error is extremely small: we have the same problem with overconfidence!</p>
<p>Note that in addition to the coefficients at the bottom, we also get goodness of fit measures such as log-likelihood, deviance, and chi-squared: we’ll talk a little more about these and what they mean later.</p>
<p>For now, let’s try the negative binomial model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">negbin_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span>
    <span class="n">ok_turbines</span><span class="o">.</span><span class="n">totals</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">ok_turbines</span><span class="o">.</span><span class="n">year</span><span class="p">),</span>
    <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">NegativeBinomial</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">negbin_results</span> <span class="o">=</span> <span class="n">negbin_model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">negbin_results</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:                 totals   No. Observations:                   17
Model:                            GLM   Df Residuals:                       15
Model Family:        NegativeBinomial   Df Model:                            1
Link Function:                    log   Scale:                          1.0000
Method:                          IRLS   Log-Likelihood:                -134.14
Date:                Wed, 17 Feb 2021   Deviance:                       7.1483
Time:                        12:51:51   Pearson chi2:                     1.90
No. Iterations:                    11                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
const          4.2059      0.544      7.725      0.000       3.139       5.273
year           0.2389      0.043      5.514      0.000       0.154       0.324
==============================================================================
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/chapters/03"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup-and-imports">Setup and imports</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#log-transforming-data">Log-transforming data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-model">Bayesian model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#count-regression">Count regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#poisson-regression">Poisson regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#negative-binomial-regression">Negative binomial regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-happened-to-the-priors">What happened to the priors?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generalized-linear-models">Generalized Linear Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#frequentist-glms">Frequentist GLMs</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Data 102 Staff
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
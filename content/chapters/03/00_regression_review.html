

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Regression review &#8212; Data, Inference, and Decisions</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/chapters/03/00_regression_review';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="prev" title="Generalized Linear Models" href="intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Data, Inference, and Decisions</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Data, Inference, and Decisions
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../01/intro.html">Chapter 1: Binary Decision-Making</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../01/01_decisions_and_errors.html">Binary Decision-Making and Error Rates</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01/02_hypothesis_testing.html">Hypothesis Testing and p-Values</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01/03_multiple_tests.html">Multiple Hypothesis Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01/04_binary_classification.html">Binary Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01/05_decision_theory.html">Decision Theory</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../02/intro.html">Chapter 2: Bayesian modeling</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../02/01_parameter_estimation.html">Parameter Estimation and Bayesian Inference Fundamentals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/02_hierarchical_models.html">Hierarchical Bayesian Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/03_graphical_models.html">Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/04_inference_sampling.html">Bayesian Inference and Sampling</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="intro.html">Chapter 3: Generalized linear models</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Multiple Linear Regression Review</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/ds-102/ds-102-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/ds-102/ds-102-book/issues/new?title=Issue%20on%20page%20%2Fcontent/chapters/03/00_regression_review.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/content/chapters/03/00_regression_review.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Regression review</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#one-dimension">One dimension</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-dimensions">Multiple dimensions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihoods-and-loss-functions">Likelihoods and loss functions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-functions">Loss functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihood-and-noise">Likelihood and noise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">Logistic regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#examples">Examples</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="regression-review">
<h1>Regression review<a class="headerlink" href="#regression-review" title="Permalink to this heading">#</a></h1>
<p>Recall that regression is a form of supervised learning. Given some data <span class="math notranslate nohighlight">\(x\)</span> (typically a scalar or a vector), we’re trying to predict a single value <span class="math notranslate nohighlight">\(y\)</span>. You’ve seen cases where <span class="math notranslate nohighlight">\(y\)</span> is a real number (linear regression) or a binary value <span class="math notranslate nohighlight">\(\in \{0, 1\}\)</span> (logistic regression). Let’s briefly review the setup for linear regression.</p>
<p>We have a collection of data <span class="math notranslate nohighlight">\((x_1, y_1), \ldots, (x_n, y_n)\)</span>. We’re trying to predict <span class="math notranslate nohighlight">\(y_i\)</span> from <span class="math notranslate nohighlight">\(x_i\)</span>, but our prediction won’t be perfect. We’ll use the notation <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> to represent the predicted value for data point <span class="math notranslate nohighlight">\(i\)</span>. We start by discussing how to get the predictions, and then move on to the relationship between the predictions and the actual observed values.</p>
<section id="one-dimension">
<h2>One dimension<a class="headerlink" href="#one-dimension" title="Permalink to this heading">#</a></h2>
<p>In one dimension, we have data in the form <span class="math notranslate nohighlight">\((x_1, y_1), \ldots, (x_n, y_n)\)</span>, where each <span class="math notranslate nohighlight">\(x_i\)</span> is a scalar and each <span class="math notranslate nohighlight">\(y_i\)</span> is a scalar. We form a linear prediction</p>
<div class="math notranslate nohighlight">
\[
\hat{y}_i = ax_i + b,
\]</div>
<p>where <span class="math notranslate nohighlight">\(a\)</span> is a slope and <span class="math notranslate nohighlight">\(b\)</span> is an intercept. In one-dimensional linear regression, we compute <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> from the observed data points <span class="math notranslate nohighlight">\((x_1, y_1), \ldots, (x_n, y_n)\)</span>.</p>
</section>
<section id="multiple-dimensions">
<h2>Multiple dimensions<a class="headerlink" href="#multiple-dimensions" title="Permalink to this heading">#</a></h2>
<p>In multiple linear regression, we still have data in the form <span class="math notranslate nohighlight">\((x_1, y_1), \ldots, (x_n, y_n)\)</span>, but now each <span class="math notranslate nohighlight">\(x_i \in \mathbb{R}^d\)</span> is a <span class="math notranslate nohighlight">\(d\)</span>-dimensional vector. We can write</p>
<div class="math notranslate nohighlight">
\[
x_i = \left(x_{i1}, x_{i2}, \ldots, x_{id}\right)
\]</div>
<p>Each entry of this vector corresponds to a different feature that we’re using in our prediction. See the examples section below for some concrete examples of what this might look like.</p>
<p>In multiple linear regression, we form our prediction for data point <span class="math notranslate nohighlight">\(i\)</span>, <span class="math notranslate nohighlight">\(y_i\)</span>, as follows:</p>
<div class="math notranslate nohighlight">
\[
\hat{y}_i = \sum_j \beta_j x_{ij}
\]</div>
<p>The <span class="math notranslate nohighlight">\(d\)</span>-dimensional vector <span class="math notranslate nohighlight">\(\beta = (\beta_1, \ldots, \beta_d)\)</span> contains the coefficients for each feature: linear regression involves figuring out what these are. We can write this in vector notation using the vectors <span class="math notranslate nohighlight">\(\beta\)</span> and <span class="math notranslate nohighlight">\(x_i\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\hat{y}_i = \beta^T x_i = x_i^T \beta
\]</div>
<p>We can take this notation one step further, and construct a matrix with all the <span class="math notranslate nohighlight">\(x\)</span> values for all data points and all features.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
X = \begin{pmatrix}
    x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1d} \\
    x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2d} \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nd}
    \end{pmatrix}
\end{split}\]</div>
<p>One entry of this matrix, <span class="math notranslate nohighlight">\(x_{ij}\)</span>, represents feature <span class="math notranslate nohighlight">\(j\)</span> for data point <span class="math notranslate nohighlight">\(i\)</span>. If we consider the entire vector of predictions <span class="math notranslate nohighlight">\(\hat{y} = \left(\hat{y}_1, \ldots, \hat{y}_n\right)\)</span>, we can write the predictions in a fully vectorized way:</p>
<div class="math notranslate nohighlight">
\[
\hat{y} = X\beta
\]</div>
</section>
<section id="likelihoods-and-loss-functions">
<h2>Likelihoods and loss functions<a class="headerlink" href="#likelihoods-and-loss-functions" title="Permalink to this heading">#</a></h2>
<p>In order to compute the vector of coefficients <span class="math notranslate nohighlight">\(\beta\)</span>, we need some way to connect the predictions <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> (which are based on <span class="math notranslate nohighlight">\(\beta\)</span>) with the actual observed values <span class="math notranslate nohighlight">\(y_i\)</span>. You’ve seen two ways of doing this:</p>
<ol class="arabic simple">
<li><p>A loss function between the prediction <span class="math notranslate nohighlight">\(\hat{y}\)</span> and the observed value <span class="math notranslate nohighlight">\(y\)</span>; we can minimize this loss function to find <span class="math notranslate nohighlight">\(\beta\)</span>.</p></li>
<li><p>A probabilistic model that describes the errors <span class="math notranslate nohighlight">\(\epsilon = y - \hat{y}\)</span> as random variables, and tries to maximize the likelihood of the data under that model.</p></li>
</ol>
<section id="loss-functions">
<h3>Loss functions<a class="headerlink" href="#loss-functions" title="Permalink to this heading">#</a></h3>
<p>Recall that in linear regression, we try to find the value of <span class="math notranslate nohighlight">\(y\)</span> that minimizes the mean squared error (MSE). We can write the RMSE as follows:</p>
<div class="math notranslate nohighlight">
\[
\text{MSE} = \frac{1}{n}\sum_i (y_i - \beta^T x_i)^2
\]</div>
<p>We can also write it as the <a class="reference external" href="https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm"><span class="math notranslate nohighlight">\(\ell_2\)</span> norm</a> of the vector <span class="math notranslate nohighlight">\(y - \hat{y}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\text{MSE} = \frac{1}{n}\left\|y - \hat{y}\right\|_2^2 = \frac{1}{n}\left\|y - X\beta\right\|_2^2
\]</div>
<p>where for any vector <span class="math notranslate nohighlight">\(z\)</span>, the <span class="math notranslate nohighlight">\(\ell_2\)</span> norm of <span class="math notranslate nohighlight">\(z\)</span> is <span class="math notranslate nohighlight">\(\|z\|_2 = \sqrt{\sum_i z_i^2}\)</span>.</p>
<p>We want to choose a value for <span class="math notranslate nohighlight">\(\beta\)</span> that makes this as small as possible:</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta} = \text{argmin}_\beta \|y - X\beta\|_2^2
\]</div>
</section>
<section id="likelihood-and-noise">
<h3>Likelihood and noise<a class="headerlink" href="#likelihood-and-noise" title="Permalink to this heading">#</a></h3>
<p>We can also describe the errors in our model:</p>
<div class="math notranslate nohighlight">
\[
y_i = \beta^T x_i + \epsilon_i,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\epsilon_i \sim N(0, \sigma^2)\)</span> is a random variable that represents the noise, or error, in the observed value. We can vectorize this noise, too: we’ll write <span class="math notranslate nohighlight">\(\epsilon = (\epsilon_1, \ldots, \epsilon_n)\)</span> so that the vector <span class="math notranslate nohighlight">\(\epsilon\)</span> has a multivariate normal distribution <span class="math notranslate nohighlight">\(\epsilon \sim N(0, \sigma^2 I_n)\)</span>. We can then write:</p>
<div class="math notranslate nohighlight">
\[
y = X\beta + \epsilon,
\]</div>
<p>or equivalently, using properties of the normal distribution,</p>
<div class="math notranslate nohighlight">
\[
y | \beta \sim N(X\beta, \sigma^2 I_n).
\]</div>
<p>Under this model, one reasonable way to estimate <span class="math notranslate nohighlight">\(\beta\)</span> is to choose the value that maximizes the likelihood. When choosing a value of <span class="math notranslate nohighlight">\(\beta\)</span> to maximize the likelihood, we note that we don’t actually care about the normalizing constant in the normal distribution. So, we can write:</p>
<p>\begin{align}
\hat{\beta}
&amp;= \text{argmax}<em>\beta \exp\left{-\frac{1}{2}(y - X\beta)^T(\sigma^2 I_n)^{-1}(y-X\beta)^T\right} \
&amp;= \text{argmax}</em>\beta \exp\left{-\frac{1}{2\sigma^2}|y - X\beta|_2^2\right}
\end{align}</p>
<p>Maximizing a quantity inside an exponential is hard. So, we’ll take advantage of the fact that the <span class="math notranslate nohighlight">\(\log\)</span> function is monotonically increasing. Furthermore, we’ll make this a minimization rather than a maximization. In general, for any well-behaved function <span class="math notranslate nohighlight">\(f\)</span>:</p>
<p>\begin{align}
\text{argmax}<em>\theta f(\theta)
&amp;= \text{argmax}</em>\theta \log(f(\theta)) \
&amp;= \text{argmin}_\theta \left[-\log(f(\theta))\right] \
\end{align}</p>
<p>So, we can write:</p>
<p>\begin{align}
\hat{\beta}
&amp;= \text{argmax}_\beta \exp\left{-\frac{1}{2\sigma^2}|y - X\beta|<em>2^2\right} \
&amp;= \text{argmin}</em>\beta \left[\frac{1}{2\sigma^2}|y - X\beta|<em>2^2 \right]\
&amp;= \text{argmin}</em>\beta |y - X\beta|_2^2
\end{align}</p>
<p>So, we’ve found that maximizing the Gaussian likelihood of the data is exactly equivalent to minimizing the squared loss. This is true in general for regression problems: we can arrive at the same answer by either choosing a loss function and minimizing it, or choosing a corresponding likelihood and maximizing it.</p>
</section>
</section>
<section id="logistic-regression">
<h2>Logistic regression<a class="headerlink" href="#logistic-regression" title="Permalink to this heading">#</a></h2>
<p>Recall that in logistic regression, we’re trying to predict binary outputs: <span class="math notranslate nohighlight">\(y_i \in \{0, 1\}\)</span>. We’re trying to predict the <strong>probability</strong> that <span class="math notranslate nohighlight">\(y_i\)</span> will be 1, which we’ll call <span class="math notranslate nohighlight">\(\hat{y}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\hat{y}_i = \sigma(\beta^T x_i),
\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma\)</span> is the sigmoid function, which converts real values to values between 0 and 1. To find <span class="math notranslate nohighlight">\(\beta\)</span>, we minimize the binary cross-entropy loss:</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta} = \text{argmin}_\beta \sum_i -\left[ y_i \ln(\hat{y}_i) + (1-y_i) \ln(1-\hat{y}_i) \right]
\]</div>
<p>You’ll show on the discussion worksheet that if we assume the likelihood model for <span class="math notranslate nohighlight">\(y\)</span> is Bernoulli with parameter <span class="math notranslate nohighlight">\(\sigma(\beta^T x_i)\)</span>, then maximizing the likelihood is equivalent to minimizing the binary cross-entropy loss.</p>
<p>For a deeper refresher on logistic regression, see <a class="reference external" href="https://www.textbook.ds100.org/ch/23/classification_intro.html">Chapter 23 of the Data 100 textbook</a>. Note that our notation is slightly different:</p>
<ul class="simple">
<li><p>We’re using <span class="math notranslate nohighlight">\(\beta\)</span> instead of <span class="math notranslate nohighlight">\(\theta\)</span> for the coefficients</p></li>
<li><p>We’re using <span class="math notranslate nohighlight">\(\hat{y}\)</span> for the predictions instead of <span class="math notranslate nohighlight">\(f_{\hat{\theta}}\)</span>.</p></li>
</ul>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this heading">#</a></h2>
<p><em>Coming soon</em></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/chapters/03"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Generalized Linear Models</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#one-dimension">One dimension</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-dimensions">Multiple dimensions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihoods-and-loss-functions">Likelihoods and loss functions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-functions">Loss functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihood-and-noise">Likelihood and noise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">Logistic regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#examples">Examples</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Data 102 Staff
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
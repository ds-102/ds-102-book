{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confirmed-death",
   "metadata": {},
   "source": [
    "# Hypotheses and decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-western",
   "metadata": {},
   "source": [
    "Many real-world data science problems boil down to making binary decisions:\n",
    "* Given the outcome of a medical test for a particular disease, does someone have that disease?\n",
    "* Given the results of experimenting with a new version of my website, does that version increase the chances that a customer will stay on my website longer and/or buy something?\n",
    "* Is there a \"statistically significant\" association between this pair of variables in my dataset?\n",
    "\n",
    "We'll focus on the case of making a binary (0/1) decision, and look at both *Reality* and our *Decision*. We'll  abbreviate Reality and Decision with $R$ and $D$ respectively. Let's illustrate this with a 2 x 2 table:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-johnston",
   "metadata": {},
   "source": [
    "\n",
    "| | $D=0$ | $D=1$ |\n",
    "| --- | --- | --- |\n",
    "|$R=0$ |  |  |\n",
    "|$R=1$ |  |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-monroe",
   "metadata": {},
   "source": [
    "Each decision we make must fall into one of the four cells of this table. In most real-world settings, we don't actually know which *row* our decision lands up in: we know whether we decided $D=0$ or $D=1$ (i.e., which column it's in), but we don't know the state of reality.\n",
    "\n",
    "This kind of table is often called a **confusion matrix**. There isn't a standard convention about whether to put reality in the rows or columns, so you may see them flipped in other places. In this book, we'll always use reality in the rows and the decision in the columns.\n",
    "\n",
    "We use the following names for each of the four cases: **true positive** (TP), **false positive** (FP), **true negative** (TN), and **false negative** (FN):\n",
    "\n",
    "| | $D=0$ | $D=1$ |\n",
    "| --- | --- | --- |\n",
    "|$R=0$ |   TN   |   FP   |\n",
    "|$R=1$ |   FN   |   TP   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-spending",
   "metadata": {},
   "source": [
    "Ideally, our decisions would always land in the top left or bottom right (in other words, our decision would match reality). Of course, in the real world, this is not always true: we may make errors. Depending on the problem, we may prefer to avoid one kind of error more than the other. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-catch",
   "metadata": {},
   "source": [
    "### Different error types: is one worse than the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-reference",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "moderate-dimension",
   "metadata": {},
   "source": [
    "## Making multiple decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-anxiety",
   "metadata": {},
   "source": [
    "Suppose now that we make multiple decisions, and we want to look at all of them collectively. There are several ways this situation could arise:\n",
    "\n",
    "*Testing multiple hypotheses on a single dataset*: we could be interested in asking multiple questions from a single dataset. For example, suppose we examine a genomics dataset in an Alzheimer's study. For each of thousands of genetic markers, we would like to ask whether a mutation at that location is associated with a higher risk of Alzheimer's.\n",
    "\n",
    "*Testing one hypothesis on multiple datasets*: suppose we're interested in studying whether there is an association between the use of statin drugs and the rate of heart attacks. We could conduct a meta-analysis of many studies that look at this question: each study tests the same hypothesis (i.e., is taking statin drugs associated with lower risk of heart attack?) with a different set of subjects. By looking at the studies as a collection, we can try to draw a stronger conclusion about the presence (or absence) of such a link.\n",
    "\n",
    "### From numbers to decisions\n",
    "\n",
    "Note that in most of these cases, each individual test doesn't just give us a single yes/no answer: instead, we typically get a $p$-value (or some other numerical value, often between 0 and 1).\n",
    "\n",
    "Note that we have no requirement that the different tests are independent! In most of the above cases, the tests (and the decisions that arise from them) are not independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-chair",
   "metadata": {},
   "source": [
    "### Row-wise error rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-being",
   "metadata": {},
   "source": [
    "We're interested in analyzing our performance. In an ideal Each one will land in one of the four cells: we can count up the total number in each quadrant, and call them $n_{00}$, $n_{01}$, and so on:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-collect",
   "metadata": {},
   "source": [
    "We're interested in analyzing our performance. Each one will land in one of the four cells: we can count up the total number in each quadrant, and call them $n_{00}$, $n_{01}$, and so on:\n",
    "\n",
    "| | $D=0$ | $D=1$ |\n",
    "| --- | --- | --- |\n",
    "| $R=0$ | $n_{00}$ | $n_{01}$ |\n",
    "| $R=1$ | $n_{10}$ | $n_{11}$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-assist",
   "metadata": {},
   "source": [
    "In traditional hypothesis testing and decision-making, we're often interested in understanding how well we do given that we know the state of reality: looking at this from the point of view of the table, we're interested in *row-wise* rates. \n",
    "\n",
    "For example, we might want to know: when reality is 0, how often do we correctly make a decision of 0? This quantity is called the **true negative rate (TNR)**. We can define a set of four row-wise rates that capture how well we do relative to reality:\n",
    "\n",
    "| | Description | Formula |\n",
    "| :-- | --- | --- |\n",
    "| **True negative rate (TNR)** | When $R=0$, how often do we correctly decide $D=0$? | $\\frac{n_{00}}{n_{00} + n_{01}}$ |\n",
    "| **False positive rate (FPR)** | When $R=0$, how often do we incorrectly decide $D=1$? | $\\frac{n_{01}}{n_{00} + n_{01}}$ |\n",
    "| **True positive rate (TPR)** | When $R=1$, how often do we correctly decide $D=0$? | $\\frac{n_{11}}{n_{10} + n_{11}}$ |\n",
    "| **False negative rate (FNR)** | When $R=1$, how often do we incorrectly decide $D=0$? | $\\frac{n_{10}}{n_{10} + n_{11}}$ |\n",
    "\n",
    "These row-wise rates look at the top row and bottom row completely separately, evaluating decisions depending on reality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-confidence",
   "metadata": {},
   "source": [
    "### Classical hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-firewall",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Multiple Hypothesis Testing &#8212; Data, Inference, and Decisions</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/chapters/01/03_multiple_tests';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Binary Classification" href="04_binary_classification.html" />
    <link rel="prev" title="Hypothesis Testing" href="02_hypothesis_testing.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Data, Inference, and Decisions</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Data, Inference, and Decisions
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="intro.html">Chapter 1: Binary Decision-Making</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_decisions_and_errors.html">Binary Decision-Making and Error Rates</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_hypothesis_testing.html">Hypothesis Testing and p-Values</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Multiple Hypothesis Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_binary_classification.html">Binary Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_decision_theory.html">Decision Theory</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../02/intro.html">Chapter 2: Bayesian modeling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../02/01_parameter_estimation.html">Parameter Estimation and Bayesian Inference Fundamentals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/02_hierarchical_models.html">Hierarchical Bayesian Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/03_graphical_models.html">Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/04_inference.html">Bayesian Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/05_inference_with_sampling.html">Bayesian Inference with Sampling</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../03/intro.html">Chapter 3: Prediction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../03/01_prediction.html">Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/02_regression_review.html">Linear Regression Review</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/03_glms.html">Generalized Linear Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/04_model_checking.html">Model Checking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/05_uncertainty_quantification.html">Uncertainty Quantification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/06_nonparametric.html">Nonparametric Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/07_neural_networks.html">Neural Networks</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../04/intro.html">Chapter 4: Causal Inference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../04/01_association_correlation_causation.html">Understanding Association</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/02_quantifying_association.html">Quantifying Association</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/03_causality_potential_outcomes.html">Causality and Potential Outcomes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/04_randomized_experiments.html">Causality in Randomized Experiments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/05_observational_studies_unconfoundedness.html">Causality in Observational Studies: Unconfoundedness</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/06_instrumental_variables.html">Causality in Observational Studies: Natural Experiments</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../05/intro.html">Chapter 5: Tail Bounds and Concentration Inequalities</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../05/01_concentration.html">Tail Bounds and Concentration Inequalities</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/ds-102/ds-102-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/ds-102/ds-102-book/issues/new?title=Issue%20on%20page%20%2Fcontent/chapters/01/03_multiple_tests.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/content/chapters/01/03_multiple_tests.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Multiple Hypothesis Testing</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-testing-and-the-replication-crisis">Multiple testing and the replication crisis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#different-approaches-to-multiple-testing">Different approaches to multiple testing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#randomness-fwer-fdr-and-fdp">Randomness, FWER, FDR, and FDP</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#known-and-unknown">Known and Unknown</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bonferroni-correction">Bonferroni correction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#controlling-fdr">Controlling FDR</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-control-fdr-instead-of-fwer">Why control FDR instead of FWER?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-benjamini-hochberg-procedure">The Benjamini-Hochberg Procedure</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-visual-comparison-of-naive-thresholding-bonferroni-and-benjamini-hochberg">A Visual Comparison of Naive thresholding, Bonferroni, and Benjamini-Hochberg</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-why-does-benjamini-hochberg-control-fdr">(Optional) Why does Benjamini-Hochberg Control FDR?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-and-contrasting-fwer-and-fdr">Comparing and Contrasting FWER and FDR</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="multiple-hypothesis-testing">
<h1>Multiple Hypothesis Testing<a class="headerlink" href="#multiple-hypothesis-testing" title="Link to this heading">#</a></h1>
<div class="cell tag_hide-cell docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell content</p>
<p class="expanded admonition-title">Hide code cell content</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>  <span class="c1"># This helps make our plots look nicer</span>

<span class="c1"># These make our figures bigger</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span>
</pre></div>
</div>
</div>
</details>
</div>
<section id="multiple-testing-and-the-replication-crisis">
<h2>Multiple testing and the replication crisis<a class="headerlink" href="#multiple-testing-and-the-replication-crisis" title="Link to this heading">#</a></h2>
<p>So far, we’ve looked at false positive rate (FPR) and true positive rate (TPR, or power) when evaluating a single hypothesis test. We saw that when using the traditional null hypothesis significance testing (NHST) framework, we choose a p-value threshold, which is our FPR for each test. If we choose a simple alternative hypothesis, we can compute the TPR by looking at the probability of making a discovery under that alternative hypothesis (i.e., the probability that our test statistic is above our decision threshold under that simple alternative hypothesis).</p>
<p>But in many cases, controlling the false positive rate might not be enough to give us the desired level of errors. To help illustrate this, we’ll consider three researchers conducting hypothetical studies of associations between how much margarine people eat and how many books they read in a year:</p>
<ul class="simple">
<li><p>Researcher Nat conducts one test, looking at a random sample of all individuals in the US.</p></li>
<li><p>Researcher Stan conducts fifty tests, looking at fifty random samples, one from each state in the US.</p></li>
<li><p>Researcher Colin conducts 3,244 tests, looking at 3,244 random samples, one from each county in the US.</p></li>
</ul>
<p>Suppose all three of them use a p-value threshold of 0.05: this means that they should have only a <span class="math notranslate nohighlight">\(5\%\)</span> chance of finding false positives. Also, since the premise of the study is somewhat absurd, we can safely assume that <em>in every test, the null hypothesis is true</em>: in other words, there is no correlation between margarine consumption and reading books. If that’s the case, what is the expected number of false positives each one will find?</p>
<p>The number of FPs each researcher finds is a Bernoulli random variable with parameter <span class="math notranslate nohighlight">\(p=0.05\)</span> and <span class="math notranslate nohighlight">\(n \in \{1, 50, 3244\}\)</span> depending on the researcher. So, the expected number of false positives is <span class="math notranslate nohighlight">\(np\)</span>:</p>
<ul class="simple">
<li><p>Nat’s expected number of false positives is <span class="math notranslate nohighlight">\(0.05 \times 1 = 0.05\)</span>: this is very close to 0.</p></li>
<li><p>Stan’s expected number of false positives is <span class="math notranslate nohighlight">\(0.05 \times 50 = 2.5\)</span>: in other words, even though the null hypothesis is true, Stan should expect to have 2-3 states come up as false positives.</p></li>
<li><p>Colin’s expected number of false positives is <span class="math notranslate nohighlight">\(0.05 \times 3244 = 162.2\)</span>: Colin should expect to have, on average, 162 counties come up as false positives.</p></li>
</ul>
<p>These false positives could have serious impacts! Stan’s study, if covered poorly in the news, could result in dramatic headlines like “California and Idaho show strong link between margarine consumption and reading: should elementary schools serve more margarine to improve reading rates?” While this example seems somewhat silly since it’s obvious that the associations are spurious, this happens often when researchers use poor statistical practices.</p>
<p>A <span class="math notranslate nohighlight">\(p\)</span>-value threshold of <span class="math notranslate nohighlight">\(0.05\)</span> means that we should expect that when the null hypothesis is true, <span class="math notranslate nohighlight">\(5\%\)</span> of the time, we’ll incorrectly make a discovery. This adds up when doing lots of tests.</p>
<p>This issue can often come up when researchers are deciding which associations to test. For example, a researcher might be interested in the effect of Vitamin D supplements on overall health. If an initial analysis of the data returns no results, the researcher might try to see if the effects are different for people of different genders. If that turns up no results, the researcher might think that Vitamin D absorption from the sun depends on melanin in skin, so they might look at the effect for all six different <a class="reference external" href="https://en.wikipedia.org/wiki/Fitzpatrick_scale">Fitzpatrick skin types</a>. At this point, in what might be a fairly innocuous sequence of tests, the researcher has already conducted 9 different tests, and the probability of making at least one false positive is<span class="math notranslate nohighlight">\(~1 - \left(1-0.05\right)^9 \approx 0.37\)</span>.</p>
<section id="different-approaches-to-multiple-testing">
<h3>Different approaches to multiple testing<a class="headerlink" href="#different-approaches-to-multiple-testing" title="Link to this heading">#</a></h3>
<p>We’ve seen that when we conduct multiple hypothesis tests at a fixed <span class="math notranslate nohighlight">\(p\)</span>-value threshold, we can control the FPR of each test, but we don’t necessarily control the rate of making errors across multiple tests. In order to address this, we’ll define error rates involving all the tests we conduct, and find algorithms that control those error rates. We’ll let <span class="math notranslate nohighlight">\(m\)</span> be the number of hypothesis tests, and define two error rates:</p>
<ul class="simple">
<li><p>The <strong>family-wise error rate (FWER)</strong> is the probability of any one of the <span class="math notranslate nohighlight">\(m\)</span> tests resulting in a false positive.</p></li>
<li><p>The <strong>false discovery rate (FDR)</strong> is the expected value of the false discovery proportion (FDP) for the <span class="math notranslate nohighlight">\(m\)</span> tests.</p></li>
</ul>
<p>We’ll explore two algorithms that we can apply to the <span class="math notranslate nohighlight">\(p\)</span>-values obtained from all <span class="math notranslate nohighlight">\(m\)</span> tests: Bonferroni correction, which controls FWER, and the Benjamini-Hochberg procedure, which controls FDR. Here, “controls” means that we’re guaranteeing that error rate will be below a certain value we choose. Once we describe the algorithms, we’ll discuss the tradeoffs between the two, and how those tradeoffs are related to the inherent properties of the two error rates.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
        <iframe
            width="400"
            height="300"
            src="https://www.youtube.com/embed/6BrafO72h_w"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        </div></div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
        <iframe
            width="400"
            height="300"
            src="https://www.youtube.com/embed/ILLMDQkQl9A"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        </div></div>
</div>
</section>
</section>
<section id="randomness-fwer-fdr-and-fdp">
<h2>Randomness, FWER, FDR, and FDP<a class="headerlink" href="#randomness-fwer-fdr-and-fdp" title="Link to this heading">#</a></h2>
<p>Up until now, we’ve focused primarily on the false discovery <em>proportion</em> (FDP). From now on, we’ll look more at the false discovery <em>rate</em> (FDR), so it’s important to understand the distinction between the two. Throughout this section, we’ll take a frequentist approach, and assume that our data are random (and because our decisions are based on our data, they’re random too), and that reality is fixed and unknown.</p>
<ul class="simple">
<li><p>The FDP is the value that we obtain for any particular dataset: we obtain data, make a series of decisions, and then the false discovery proportion is based on those particular decisions.</p></li>
<li><p>The FDR is the expectation of the FDP, where the expectation is taken over the randomness in the data. In other words, the FDR is the average FDP, averaged across all possible datasets (and weighted by how likely each one is).</p></li>
<li><p>Similarly, for any particular dataset, we can define the event “at least one false positive happened”. This event either occurs or it doesn’t for any particular series of decisions. The family-wise error rate (FWER) is the probability of this event occurring for any dataset.</p></li>
</ul>
<p>In other words, the false discovery <strong>proportion</strong> is based on any particular dataset, while the false discovery <strong>rate</strong> is the average FDP across all possible datasets.</p>
<section id="known-and-unknown">
<h3>Known and Unknown<a class="headerlink" href="#known-and-unknown" title="Link to this heading">#</a></h3>
<p>Throughout this section, we’ll discuss FDP, FDR, and FWER as metrics to help us evaluate a decision-making process. But recall that in reality, we only ever observe the data and the decisions we make based on the data: reality is unknown to us. That means that in many real-world scenarios, we can’t actually compute the FDP for any particular series of decisions, because it requires us to know when <span class="math notranslate nohighlight">\(R=0\)</span> and when <span class="math notranslate nohighlight">\(R=1\)</span>.</p>
<p>So if we can’t actually compute the FDP, why are we analyzing it?</p>
<p>The key is that the FDR (average FDP) provides a way of evaluating an algorithm. We’ll discuss several procedures, and show that on average, they perform well: in other words, if we look at the performance of these procedures averaged over the randomness in the data, we can mathematically show that the FDR or FWER will be below a certain level. For example, we’ll look at a procedure called Bonferroni correction and show that if we use it, our FWER, or probability of making a false positive, will be less than a particular threshold that we get to specify.</p>
<p>This process, of first defining algorithms that operate on the observed data to make decisions, then theoretically evaluating those algorithms using metrics that depend on unknown variables, is something we’ll see over and over throughout this course.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
        <iframe
            width="400"
            height="300"
            src="https://www.youtube.com/embed/G9EYjVfLLBU"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        </div></div>
</div>
</section>
</section>
<section id="bonferroni-correction">
<h2>Bonferroni correction<a class="headerlink" href="#bonferroni-correction" title="Link to this heading">#</a></h2>
<p>Bonferroni correction is a technique for controlling the FWER. In this context, when we use the term “<strong>controlling</strong> the FWER at level <span class="math notranslate nohighlight">\(\alpha\)</span>”, this just means that we want the FWER to be less than or equal to some value <span class="math notranslate nohighlight">\(\alpha\)</span> that we choose.</p>
<p>The procedure itself is very simple: it says that if we want to guarantee that our FWER for <span class="math notranslate nohighlight">\(m\)</span> tests will be less than or equal to <span class="math notranslate nohighlight">\(\alpha\)</span>, then we just need to use a <span class="math notranslate nohighlight">\(p\)</span>-value threshold of <span class="math notranslate nohighlight">\(\alpha/m\)</span> to make a decision for each test. For example, if we want to guarantee an FWER of <span class="math notranslate nohighlight">\(0.01\)</span> for <span class="math notranslate nohighlight">\(500\)</span> tests, we should use a <span class="math notranslate nohighlight">\(p\)</span>-value threshold for each test of <span class="math notranslate nohighlight">\(0.01 / 5000 = 2 \times 10^{-6}\)</span>.</p>
<p>Let’s show why this formula works. We’ll start by establishing some facts and definitions that we need.</p>
<p>To start, we’ll need to use the <a class="reference external" href="https://en.wikipedia.org/wiki/Boole%27s_inequality">union bound</a>, which states that for events <span class="math notranslate nohighlight">\(A_1, \ldots, A_m\)</span>, that
$<span class="math notranslate nohighlight">\(
P\left(\bigcup_{i=1}^m A_i\right) \leq \sum_{i=1}^m P(A_i).
\)</span>$</p>
<p>Informally, this says that if we add up the independent probabilities of the events occuring, the result will always be greater than or equal to the probability of the union of those events. Intuitively, this is true because when computing the probability of the union, we have to effectively subtract off the overlap between probabilities.</p>
<p>To use the union bound, we’ll define the indicator variables <span class="math notranslate nohighlight">\(T_1, \ldots, T_m\)</span>, where <span class="math notranslate nohighlight">\(T_i\)</span> is the event that test <span class="math notranslate nohighlight">\(i\)</span> results in a false positive. The family-wise error rate is the probability that any one of the tests is a false positive: in other words,  <span class="math notranslate nohighlight">\(FWER = P(T_1 \cup T_2 \cup T_3 \cdots \cup T_m)\)</span>. We know from the previous section that if we use the same <span class="math notranslate nohighlight">\(p\)</span>-value threshold <span class="math notranslate nohighlight">\(\gamma\)</span> for each test, then <span class="math notranslate nohighlight">\(P(T_i) = \gamma\)</span>.</p>
<p>Putting it all together, we have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
FWER 
    &amp;= P\left(\bigcup_{i=1}^m T_i\right) \\
    &amp;\leq \sum_{i=1}^m P\left(T_i\right) \\
    &amp;= m \gamma
\end{align*}
\end{split}\]</div>
<p>If we choose our <span class="math notranslate nohighlight">\(p\)</span>-value threshold for each test <span class="math notranslate nohighlight">\(\gamma\)</span> to be equal to <span class="math notranslate nohighlight">\(\alpha/m\)</span> (recall that <span class="math notranslate nohighlight">\(\alpha\)</span> is our desired FWER), then the right-hand side becomes <span class="math notranslate nohighlight">\(\alpha\)</span>, and we guarantee that our FWER is less than or equal to <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
        <iframe
            width="400"
            height="300"
            src="https://www.youtube.com/embed/zwydh-K6Sc4"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        </div></div>
</div>
</section>
<section id="controlling-fdr">
<h2>Controlling FDR<a class="headerlink" href="#controlling-fdr" title="Link to this heading">#</a></h2>
<section id="why-control-fdr-instead-of-fwer">
<h3>Why control FDR instead of FWER?<a class="headerlink" href="#why-control-fdr-instead-of-fwer" title="Link to this heading">#</a></h3>
<p>Suppose we conduct 1,000,000 tests, and we want to control the FWER at level <span class="math notranslate nohighlight">\(0.01\)</span>. If we use the Bonferroni procedure, our <span class="math notranslate nohighlight">\(p\)</span>-value threshold will be <span class="math notranslate nohighlight">\(10^{-8}\)</span>: we will only make discoveries if the <span class="math notranslate nohighlight">\(p\)</span>-values are incredibly small! This is because FWER is a very strict criterion. Controlling FWER means we want the probability of making <strong>any</strong> false positives in <span class="math notranslate nohighlight">\(m\)</span> tests to be less than or equal to <span class="math notranslate nohighlight">\(\alpha\)</span>: this requirement gets harder and harder to satisfy the larger <span class="math notranslate nohighlight">\(m\)</span> gets. This is why the <span class="math notranslate nohighlight">\(p\)</span>-value threshold from Bonferroni correction gets smaller as <span class="math notranslate nohighlight">\(m\)</span> increases.</p>
<p>Controlling FDR, on the other hand, is much more forgiving of a small number of errors. In our example above, controlling FDR at level <span class="math notranslate nohighlight">\(0.01\)</span> means that out of the discoveries we make, we want <span class="math notranslate nohighlight">\(1\%\)</span> or fewer of them to be wrong. This is still a much stricter criterion than just controlling FPR as we saw with naive thresholding, but it’s easier to satisfy as <span class="math notranslate nohighlight">\(m\)</span> grows without imposing such a drastically low <span class="math notranslate nohighlight">\(p\)</span>-value threshold. Next, we’ll see an algorithm that strikes this middle ground.</p>
</section>
<section id="the-benjamini-hochberg-procedure">
<h3>The Benjamini-Hochberg Procedure<a class="headerlink" href="#the-benjamini-hochberg-procedure" title="Link to this heading">#</a></h3>
<p>The Benjamini-Hochberg (often abbreviated to B-H) procedure is slightly more complicated than Bonferroni correction, but it also uses the same <span class="math notranslate nohighlight">\(p\)</span>-value threshold for all tests. The key is that we use the <span class="math notranslate nohighlight">\(p\)</span>-values themselves to determine the threshold. Here’s how it works, for a desired FDR <span class="math notranslate nohighlight">\(\alpha\)</span>:</p>
<ul class="simple">
<li><p>First, sort the <span class="math notranslate nohighlight">\(p\)</span>-values, and index them by <span class="math notranslate nohighlight">\(k\)</span> (i.e., the first one corresponds to <span class="math notranslate nohighlight">\(k=1\)</span>, the second one corresponds to <span class="math notranslate nohighlight">\(k=2\)</span>, and so on, until the last one corresponds to <span class="math notranslate nohighlight">\(k=m\)</span>)</p></li>
<li><p>For each sorted <span class="math notranslate nohighlight">\(p\)</span>-value, compare it to the value <span class="math notranslate nohighlight">\(\frac{k\alpha}{m}\)</span> (i.e., the smallest p-value gets compared to <span class="math notranslate nohighlight">\(\alpha/m\)</span>, the second-smallest gets compared to <span class="math notranslate nohighlight">\(2\alpha/m\)</span>, and so on, until the largest one gets compared to <span class="math notranslate nohighlight">\(\alpha\)</span>)</p></li>
<li><p>Find the largest sorted <span class="math notranslate nohighlight">\(p\)</span>-value that’s still below its comparison value</p></li>
<li><p>Use that <span class="math notranslate nohighlight">\(p\)</span>-value as the threshold</p></li>
</ul>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
        <iframe
            width="400"
            height="300"
            src="https://www.youtube.com/embed/w1yZTe7X1JM"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        </div></div>
</div>
</section>
</section>
<section id="a-visual-comparison-of-naive-thresholding-bonferroni-and-benjamini-hochberg">
<h2>A Visual Comparison of Naive thresholding, Bonferroni, and Benjamini-Hochberg<a class="headerlink" href="#a-visual-comparison-of-naive-thresholding-bonferroni-and-benjamini-hochberg" title="Link to this heading">#</a></h2>
<p>Consider the <span class="math notranslate nohighlight">\(p\)</span>-values we looked at in the last section. We’ll add a column <code class="docutils literal notranslate"><span class="pre">k</span></code> that provides the index after being sorted:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p_sorted</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;p_values.csv&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;pvalue&#39;</span><span class="p">)</span>

<span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">p_sorted</span><span class="p">)</span>  <span class="c1"># number of tests</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># index of each test in sorted order</span>

<span class="n">p_sorted</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">k</span> 
<span class="n">p_sorted</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pvalue</th>
      <th>is_alternative</th>
      <th>k</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>20</th>
      <td>0.000008</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>43</th>
      <td>0.000109</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>56</th>
      <td>0.000162</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>82</th>
      <td>0.000219</td>
      <td>1</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.000436</td>
      <td>1</td>
      <td>5</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.952674</td>
      <td>0</td>
      <td>96</td>
    </tr>
    <tr>
      <th>49</th>
      <td>0.978843</td>
      <td>0</td>
      <td>97</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.980498</td>
      <td>0</td>
      <td>98</td>
    </tr>
    <tr>
      <th>42</th>
      <td>0.982076</td>
      <td>0</td>
      <td>99</td>
    </tr>
    <tr>
      <th>31</th>
      <td>0.986542</td>
      <td>0</td>
      <td>100</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 3 columns</p>
</div></div></div>
</div>
<p>We can visualize the <span class="math notranslate nohighlight">\(p\)</span>-values in sorted order:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">p_sorted</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;pvalue&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;is_alternative&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/f534dca6baf58196f1bea5058237d3e92b881564fd060ad19e8c07f8d47e79ad.png" src="../../../_images/f534dca6baf58196f1bea5058237d3e92b881564fd060ad19e8c07f8d47e79ad.png" />
</div>
</div>
<p>Here, the <span class="math notranslate nohighlight">\(x\)</span>-axis is <span class="math notranslate nohighlight">\(k\)</span>, the index, and the <span class="math notranslate nohighlight">\(y\)</span>-axis represents the <span class="math notranslate nohighlight">\(p\)</span>-value. We can visualize the results of two techniques:</p>
<ul class="simple">
<li><p>If we use a naive <span class="math notranslate nohighlight">\(p\)</span>-value threshold of 0.05 for all tests, we will obtain an FPR of 0.05. This threshold is the black line below.</p></li>
<li><p>If we use Bonferroni correction and want a FWER of 0.05 (i.e., the probability of making any false positives at all is 0.05), then we should use a <span class="math notranslate nohighlight">\(p\)</span>-value threshold of <span class="math notranslate nohighlight">\(\frac{0.05}{100} = 0.0005\)</span>. This threshold is the red dashed line below.</p></li>
</ul>
<p>We can see that by using the more conservative Bonferroni threshold (in red), we leave</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">desired_fwer</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">p_sorted</span><span class="p">[</span><span class="s1">&#39;pvalue&#39;</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">p_sorted</span><span class="p">[</span><span class="s1">&#39;is_alternative&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Naive thresholding&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">desired_fwer</span> <span class="o">/</span> <span class="n">m</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Bonferroni&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;tab:red&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/df53eb117f8838d4e2349e84c21f83ac45b7700d2386ef84b64ed0953cb7f53c.png" src="../../../_images/df53eb117f8838d4e2349e84c21f83ac45b7700d2386ef84b64ed0953cb7f53c.png" />
</div>
</div>
<p>In this visualization, how does the Benjamini-Hochberg procedure work? We compare each <span class="math notranslate nohighlight">\(p\)</span>-value to the comparison value <span class="math notranslate nohighlight">\(\frac{k\alpha}{m}\)</span>, which in this visualization is a diagonal line. In order to better see what’s going on, we’ll also zoom in on a narrower range of <span class="math notranslate nohighlight">\(p\)</span>-values:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">desired_fdr</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">p_sorted</span><span class="p">[</span><span class="s1">&#39;pvalue&#39;</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">p_sorted</span><span class="p">[</span><span class="s1">&#39;is_alternative&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">k</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">desired_fdr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;B-H guide&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;cyan&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0005</span><span class="p">,</span> <span class="mf">0.0305</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/eb8e67b80b487e4369a92f0c5391cc4544606f1e20beaf94be9fe1b1ab33b369.png" src="../../../_images/eb8e67b80b487e4369a92f0c5391cc4544606f1e20beaf94be9fe1b1ab33b369.png" />
</div>
</div>
<p>The Benjamini-Hochberg procedure says to take the largest <span class="math notranslate nohighlight">\(p\)</span>-value that’s below the comparison value <span class="math notranslate nohighlight">\(\frac{k\alpha}{m}\)</span>: in this case, that’s the point at index 16. This becomes our <span class="math notranslate nohighlight">\(p\)</span>-value threshold, so we choose to reject the null hypothesis for the first 16 <span class="math notranslate nohighlight">\(p\)</span>-values (after being sorted). The graph below shows all three thresholds:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">desired_fdr</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">desired_fwer</span> <span class="o">=</span> <span class="mf">0.05</span>

<span class="c1"># From visually inspecting the graph above, we saw that the 16th</span>
<span class="c1">#  p-value was the last one below the reference value (cyan line)</span>
<span class="n">bh_threshold</span> <span class="o">=</span> <span class="n">p_sorted</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">p_sorted</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">16</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span>
    <span class="n">bh_threshold</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;B-H threshold (FDR=</span><span class="si">{</span><span class="n">desired_fdr</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;tab:green&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;-.&#39;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span>
    <span class="mf">0.05</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Naive threshold (FPR=0.05)&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;-&#39;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span>
    <span class="n">desired_fwer</span> <span class="o">/</span> <span class="n">m</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Bonferroni (FWER=</span><span class="si">{</span><span class="n">desired_fwer</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;tab:red&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span>
<span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">p_sorted</span><span class="p">[</span><span class="s1">&#39;pvalue&#39;</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">p_sorted</span><span class="p">[</span><span class="s1">&#39;is_alternative&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">k</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">desired_fdr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;B-H guide&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;cyan&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">42.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.06</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/81bee4e25facfe9124da1bcaa557d259583858c8e652903af8de666fb9c795be.png" src="../../../_images/81bee4e25facfe9124da1bcaa557d259583858c8e652903af8de666fb9c795be.png" />
</div>
</div>
<section id="optional-why-does-benjamini-hochberg-control-fdr">
<h3>(Optional) Why does Benjamini-Hochberg Control FDR?<a class="headerlink" href="#optional-why-does-benjamini-hochberg-control-fdr" title="Link to this heading">#</a></h3>
<p><em>Text coming soon: see video</em></p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
        <iframe
            width="400"
            height="300"
            src="https://www.youtube.com/embed/e10W3lJsBhc"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        </div></div>
</div>
</section>
</section>
<section id="comparing-and-contrasting-fwer-and-fdr">
<h2>Comparing and Contrasting FWER and FDR<a class="headerlink" href="#comparing-and-contrasting-fwer-and-fdr" title="Link to this heading">#</a></h2>
<p>Now that we’ve seen how we might control FWER and FDR, we’ll build a better understanding of when each one might be better suited for a particular problem. Recall the definitions:</p>
<ul class="simple">
<li><p>Family-wise error rate (FWER) is the probability that any of the <span class="math notranslate nohighlight">\(m\)</span> tests is a false positive.</p></li>
<li><p>False discovery rate (FDR) is the expected FDP, or equivalently, the expected fraction of discoveries that are incorrect.</p></li>
</ul>
<p>Suppose we conduct 1,000,000 tests (<span class="math notranslate nohighlight">\(m=1000000\)</span>).</p>
<p>If we want a FWER of <span class="math notranslate nohighlight">\(0.05\)</span>, this means that we want the probability of any one of the 1,000,000 tests being a false positive to be 0.05 or less. In order to control this probability, we’ll need to be very conservative: after all, even a single false positive will mean that we’ve failed. In other words, controlling FWER requires us to be very conservative, and use very small <span class="math notranslate nohighlight">\(p\)</span>-value thresholds. This typically leads to very low power, or true positive rate (TPR), because our <span class="math notranslate nohighlight">\(p\)</span>-value threshold is so low that we miss many true positives.</p>
<p>On the other hand, if we want a FDR of <span class="math notranslate nohighlight">\(0.05\)</span>, this just means that out of the discoveries we make in the 1,000,000 tests, on average, we want <span class="math notranslate nohighlight">\(95\%\)</span> or more of them to be correct. We can achieve this with a much less conservative threshold. In other words, when we control FDR, we accept some more false positives, and in return we can achieve a higher true positive rate (i.e., do better in the case where <span class="math notranslate nohighlight">\(R=1\)</span>).</p>
<p>How do these interpretations translate into choosing a rate to control in real-world applications? We’ll look at two examples to help illustrate the difference.</p>
<ul class="simple">
<li><p>Consider a medical test for a rare condition where the only treatment is a dangerous surgery. In this case, a false positive could subject a patient to unnecessarily undergo the procedure, putting the patient’s life needlessly at risk and potentially inducing medical trauma. A false negative, on the other hand, while still potentially harmful due to lack of treatment, may not be as bad. In this case, or any similar case where a false positive is much worse than a false negative, controlling FWER is likely a better choice, since controlling FWER favors false negatives over false positives.</p></li>
<li><p>Consider an online retailer who is interested in conducting many A/B tests to measure whether various website changes improve the chances that shoppers will buy products. In this case, the harm of a false positive is not particularly severe, and we can likely tolerate that <span class="math notranslate nohighlight">\(5\%\)</span> of our discoveries could be wrong, especially if it means a better chance of finding changes that increase product purchases.</p></li>
</ul>
<p>Note that both of these examples are somewhat ambiguous! In the first example, the cost of a false negative depends strongly on how much the treatment improves the prognosis for patients with the condition, whether follow-on tests exist, and so on. Similarly, in the second example, if the website changes have auxiliary costs (time and money spent by developers to make the changes, changes in user opinion about the website based on the changes, etc.), then this could affect whether we might prefer one over the other.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
        <iframe
            width="400"
            height="300"
            src="https://www.youtube.com/embed/hD6zX8zZU_A"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        </div></div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/chapters/01"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="02_hypothesis_testing.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Hypothesis Testing</p>
      </div>
    </a>
    <a class="right-next"
       href="04_binary_classification.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Binary Classification</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-testing-and-the-replication-crisis">Multiple testing and the replication crisis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#different-approaches-to-multiple-testing">Different approaches to multiple testing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#randomness-fwer-fdr-and-fdp">Randomness, FWER, FDR, and FDP</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#known-and-unknown">Known and Unknown</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bonferroni-correction">Bonferroni correction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#controlling-fdr">Controlling FDR</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-control-fdr-instead-of-fwer">Why control FDR instead of FWER?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-benjamini-hochberg-procedure">The Benjamini-Hochberg Procedure</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-visual-comparison-of-naive-thresholding-bonferroni-and-benjamini-hochberg">A Visual Comparison of Naive thresholding, Bonferroni, and Benjamini-Hochberg</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-why-does-benjamini-hochberg-control-fdr">(Optional) Why does Benjamini-Hochberg Control FDR?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-and-contrasting-fwer-and-fdr">Comparing and Contrasting FWER and FDR</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Data 102 Staff
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
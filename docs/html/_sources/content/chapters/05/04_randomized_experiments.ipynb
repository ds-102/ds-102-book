{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "moderate-constitution",
   "metadata": {},
   "source": [
    "# Causal Inference in Randomized Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-technical",
   "metadata": {},
   "source": [
    "In this section, we'll build a deeper understanding of randomized experiments. Recall from the last section the table of potential outcomes:\n",
    "\n",
    "| Unit | Outcome if not treated | Outcome if treated | Treated or not? |\n",
    "| ---  |         ---            |       ---          |      ---        |\n",
    "|  1   |      ?          |      $Y_1(1)$      |     $Z_1=1$       |\n",
    "|  2   |      $Y_2(0)$          |      ?      |     $Z_2=0$       |\n",
    "|  3   |      $Y_3(0)$          |      ?      |     $Z_3=0$       |\n",
    "|  4   |      ?          |      $Y_4(1)$      |     $Z_4=1$       |\n",
    "|  5   |      $Y_5(0)$          |      ?      |     $Z_5=0$       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-worthy",
   "metadata": {},
   "source": [
    "## Examples of randomized experiments\n",
    "\n",
    "*Coming soon*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-mortgage",
   "metadata": {},
   "source": [
    "## Randomized experiments and potential outcomes\n",
    "\n",
    "*You may have seen some of this material before in [Data 8](https://www.inferentialthinking.com/chapters/12/3/Causality.html).*\n",
    "\n",
    "In a randomized experiment, we protect ourselves from dealing with confounding variables by randomizing units into treatment and control. In other words, we choose each $Z_i$ randomly, and we choose it independent of $Y_i(0)$ and $Y_i(1)$. Mathematically, we can write:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\big(Y_i(0), Y_i(1)\\big) \\perp \\!\\!\\! \\perp Z_i\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Remember, this doesn't mean that the treatment is independent from the observed outcome! It only means that the *decision on whether or not to treat* is independent from the outcome. \n",
    "\n",
    "You may remember learning that in a randomized controlled trial, we can determine causality by using the difference in means between the treatment and control groups. Let's now show mathematically that this is true. Recall from the previous section our definition of the ATE $\\tau$:\n",
    "\n",
    "$$\\tau = E[Y_i(1) - Y_i(0)] = E[Y_i(1)] - E[Y_i(0)]$$\n",
    "\n",
    "If $Z_i$ and $Y_i$ are independent, then $E[Y_i(\\cdot)] = E[Y_i(\\cdot)|Z_i]$. In other words, conditioning on $Z_i$ shouldn't change the expectation, as long as $Z_i$ and $Y_i(\\cdot)$ are independent.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\tau\n",
    "        &= E[Y_i(1)] - E[Y_i(0)] \\\\\n",
    "        &= E[Y_i(1)|Z_i=1] - E[Y_i(0)|Z_i=0] \\quad{\\scriptsize (\\text{if }(Y_i(0), Y_i(1)) \\perp \\!\\! \\perp Z_i)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "These two terms correspond to the mean outcomes in the treatment and control groups, respectively. If we have $n$ observations $(Z_1, Y_{1,obs}), \\ldots, (Z_n, Y_{n,obs})$, then our empirical estimate for the ATE is just:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\hat{\\tau}\n",
    "        &= \\underbrace{\\left[\\frac{1}{n_1} \\sum_{i: Z_i = 1} Y_i\\right]}_{=\\bar{Y}_{obs,1}} - \\underbrace{\\left[\\frac{1}{n_0} \\sum_{i: Z_i = 0} Y_i\\right]}_{=\\bar{Y}_{obs,0}},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $n_1$ is the number of treated units and $n_0$ is the number of untreated units, and $\\bar{Y}_{obs,1}$ and $\\bar{Y}_{obs,0}$ are the means of the treatment and control groups respectively. This quantity $\\hat{\\tau}$, which you've most likely seen and used before (e.g., in Data 8), has a few names: it's called the **difference in means**, the **simple difference in mean outcomes (SDO)**, the **Neyman estimator**, or the **prima facie causal effect** (*prima facie* is latin for \"at first sight\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-language",
   "metadata": {},
   "source": [
    "## Fixed-sample assumption: Fisher and Neyman\n",
    "\n",
    "In this section, we'll analyze randomized experiments and the Neyman estimator under the fixed-sample assumption. Recall that in this setting, we assume that $Z_i$ is random, but that $Y_i(0)$ and $Y_i(1)$ are fixed. In this case, the statement of independence above doesn't really make sense, since $Y_i(0)$ and $Y_i(1)$ are not random. However, we can still compute the Neyman estimator. We'll develop some properties of the estimator, then use those to construct a confidence interval for the estimated ATE. Finally, we'll look at two different hypothesis tests used in randomized experiments.\n",
    "\n",
    "### Properties of the Neyman estimator\n",
    "The Neyman estimator has two useful properties: the first is that it's unbiased, and the second is that its variance depends on the estimated variances within the two groups:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "E[\\hat{\\tau}] &= \\tau \\\\\n",
    "\\text{var}(\\hat{\\tau}) &\\leq \\frac{\\hat{\\sigma}_1^2}{n_1} + \\frac{\\hat{\\sigma}_0^2}{n_0},\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $\\hat{\\sigma}_k$ is the sample standard deviation of the potential treatment outcomes $Y_1(k), \\ldots, Y_n(k)$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\hat{\\sigma}_k &= \n",
    "            \\frac{1}{n - 1} \\sum_{i} \\big(Y_i(k) - \\bar{Y}(k)\\big)\n",
    "\\end{align*}\n",
    "$$\n",
    "Since this depends on the counterfactual outcomes that we don't get to observe, we'll typically approximate it by replacing the true sample variances with the sample variances within each observed group in our data, and call this $\\hat{V}$:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\hat{V} &= \n",
    "    \\Bigg[\\frac{1}{n_1}\n",
    "        \\underbrace{%\n",
    "            \\frac{1}{n_1 - 1} \\sum_{i: Z_i = 1} \\big(Y_i - \\bar{Y}_{obs,1}\\big)^2}_{%\n",
    "            \\text{sample std. dev. of treatment group}}\\Bigg] +\n",
    "    \\Bigg[\\frac{1}{n_0}\n",
    "        \\underbrace{%\n",
    "            \\frac{1}{n_0 - 1} \\sum_{i: Z_i = 0} \\big(Y_i - \\bar{Y}_{obs,0}\\big)^2}_{%\n",
    "            \\text{sample std. dev. of control group}}\\Bigg]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "It can be shown that under certain regularity conditions, as the number of samples grows larger, the distribution of the quantity $\\frac{\\hat{\\tau} - \\tau}{\\sqrt{\\hat{V}}}$ converges to a normal distribution $N(0, \\sigma^2)$, where $\\sigma^2 < 1$.\n",
    "\n",
    "### Confidence intervals for the ATE\n",
    "\n",
    "Given the fact above, we can construct an asymptotically valid $95\\%$ confidence interval for $\\tau$ as follows:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\left(\\hat{\\tau} - 1.96\\sqrt{\\hat{V}}, \\hat{\\tau} + 1.96\\sqrt{\\hat{V}}\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### Hypothesis testing for causal effects\n",
    "\n",
    "In the classic null hypothesis significance testing framework, there are two different null hypotheses commonly used when measuring causal effects in randomized trials:\n",
    "\n",
    "1. **Fisher's strong null** (also known as Fisher's sharp null) states that for every unit, the treatment effect $Y_i(1) - Y_i(0) = 0$.\n",
    "2. **Neyman's weak null** states that the average treatment effect is 0. In other words, even if some individual treatment effects are positive and some are negative, they average out to 0.\n",
    "\n",
    "The first is a much stricter null hypothesis (hence the name \"strong null\"), since it states that all the treatment effects are 0. The second is looser, requiring only that the treatment effects average out to 0. Because of this, the strong null is often easier to reject.\n",
    "\n",
    "To test a hypothesis against Neyman's weak null, we construct the test statistic $\\frac{\\hat{\\tau}}{\\sqrt{\\hat{V}}}$. Under the Neyman weak null hypothesis, this should follow a standard normal distribution.\n",
    "\n",
    "To test a hypothessis against Fisher's strong null, we need some stronger mathematical machinery. We'll limit ourself to cases where the treatment and outcome are both binary, and use a technique called **permutation testing**. In this technique, we randomly shuffle the treatment/control labels, and use that to build a null distribution for the difference in outcomes (for a refresher on this technique, see the [Data 8 textbook](https://www.inferentialthinking.com/chapters/12/1/AB_Testing.html)). Instead of randomly shuffling, however, Fisher's exact test instead looks at every single possible permutation, and computes a $p$-value in closed form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-target",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "protected-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-joshua",
   "metadata": {},
   "source": [
    "## Complications with randomized experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-humanity",
   "metadata": {},
   "source": [
    "*In progress*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-office",
   "metadata": {},
   "source": [
    "### Compliance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-feature",
   "metadata": {},
   "source": [
    "### External validity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
